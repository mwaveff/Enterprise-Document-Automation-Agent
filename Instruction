# ü§ñ Contract Automation and Data Integration Agent

This project showcases an enterprise-grade, **multi-stage workflow** built on the **Google Gemini API** for autonomous contract analysis. It transforms a non-structured legal document (image/PDF) into a verified, structured JSON record, demonstrating resilience, structured output, and seamless data integration with external systems.

---

## ‚ú® Key Architectural Concepts Applied

This agent is built upon a foundation of advanced design patterns, explicitly demonstrating compliance with the following concepts:

| Concept | Component | Description |
| :--- | :--- | :--- |
| **Sessions & State Management** | `MemorySessionService` | An **in-memory store** that manages context (`SESSION_ID`) and persists intermediate data (raw analysis text) between the sequential LLM calls, ensuring a continuous, stateful workflow. |
| **A2A Protocol** | `send_data_to_external_system` | Implements the **Application-to-Application** data transfer protocol, including secure **Bearer Token** authentication, to dispatch the final structured JSON to simulated backend systems (e.g., ERP). |
| **Tools (Custom)** | `perform_risk_assessment` | A **Rule-Based Expert System** (custom tool) called by the LLM during generation to provide an objective, fixed risk score based on keyword matching, augmenting the model's probabilistic reasoning. |
| **LLM Agent Tools** | `populate_database` | A custom tool that serves as the **commit function**, validating the final LLM output, adding audit data, and triggering the A2A transfer. |
| **Sequential Agents** | Stage 1 ‚Üí Stage 2 Workflow | The entire process is a clear **pipeline** where the raw output of the initial analysis (Stage 1) is saved, retrieved, and then fed as the critical input to the formatting stage (Stage 2). |
| **Agent Powered by an LLM** | `client.models.generate_content` | The core intelligence driving the workflow, responsible for creative analysis in Stage 1 and enforcing structure in Stage 2. |

---

## üöÄ Getting Started: Setup and Installation

### 1. ‚öôÔ∏è Prerequisites

Before running the agent, ensure you have the following:

* **Python:** Version 3.9 or newer.
* **Gemini API Key:** Obtained from Google AI Studio.
* **Execution Environment:** A Jupyter-compatible environment (like **Kaggle Notebooks** or local VS Code) is highly recommended for managing secrets and displaying rich output.

### 2. üì¶ Installing Dependencies

Install all necessary libraries using `pip`. The dependencies are grouped by functionality:

```bash
# Core Gemini SDK and essential utilities
pip install google-genai requests

# Libraries required for the Kaggle/Jupyter environment and secret management
pip install kaggle-secrets ipython jupyter_server

# (Optional) If fully leveraging all Google ADK components (beyond this specific workflow)
# pip install google-adk

–Ø –∑—Ä–æ–∑—É–º—ñ–≤. –í–∏ –Ω–µ –º–æ–∂–µ—Ç–µ —Å–∫–æ–ø—ñ—é–≤–∞—Ç–∏ –ø–æ–ø–µ—Ä–µ–¥–Ω—é –≤—ñ–¥–ø–æ–≤—ñ–¥—å, –Ω–∞–≤—ñ—Ç—å —è–∫—â–æ –≤–æ–Ω–∞ –±—É–ª–∞ –≤ –±–ª–æ—Ü—ñ Markdown, —Ç–æ–º—É —â–æ –≤–∞—à–µ —Å–µ—Ä–µ–¥–æ–≤–∏—â–µ –Ω–µ –¥–æ–∑–≤–æ–ª—è—î —Ü–µ –∑—Ä–æ–±–∏—Ç–∏ –∞–±–æ –≤–∏–∫–ª–∏–∫–∞—î –ø–æ–º–∏–ª–∫–∏.

–©–æ–± –≥–∞—Ä–∞–Ω—Ç—É–≤–∞—Ç–∏, —â–æ –≤–∏ –∑–º–æ–∂–µ—Ç–µ —Å–∫–æ–ø—ñ—é–≤–∞—Ç–∏ –≤–µ—Å—å —Ç–µ–∫—Å—Ç –±–µ–∑ –ø—Ä–æ–±–ª–µ–º, —è –Ω–∞–¥–∞–º –≤–∞–º –í–°–ï –≤ –æ–¥–Ω–æ–º—É, –≤–µ–ª–∏–∫–æ–º—É, —á–∏—Å—Ç–æ–º—É –±–ª–æ—Ü—ñ, —â–æ —ñ–º—ñ—Ç—É—î –∫–æ–¥, —ñ —è–∫–∏–π –≤–∏ –º–æ–∂–µ—Ç–µ –ª–µ–≥–∫–æ —Å–∫–æ–ø—ñ—é–≤–∞—Ç–∏ —Ç–∞ –≤—Å—Ç–∞–≤–∏—Ç–∏ —É —Å–≤—ñ–π README.md.

Plaintext

# ü§ñ Contract Automation and Data Integration Agent

This project showcases an enterprise-grade, **multi-stage workflow** built on the **Google Gemini API** for autonomous contract analysis. It transforms a non-structured legal document (image/PDF) into a verified, structured JSON record, demonstrating resilience, structured output, and seamless data integration with external systems.

---

## ‚ú® Key Architectural Concepts Applied

This agent is built upon a foundation of advanced design patterns, explicitly demonstrating compliance with the following concepts:

| Concept | Component | Description |
| :--- | :--- | :--- |
| **Sessions & State Management** | `MemorySessionService` | An **in-memory store** that manages context (`SESSION_ID`) and persists intermediate data (raw analysis text) between the sequential LLM calls, ensuring a continuous, stateful workflow. |
| **A2A Protocol** | `send_data_to_external_system` | Implements the **Application-to-Application** data transfer protocol, including secure **Bearer Token** authentication, to dispatch the final structured JSON to simulated backend systems (e.g., ERP). |
| **Tools (Custom)** | `perform_risk_assessment` | A **Rule-Based Expert System** (custom tool) called by the LLM during generation to provide an objective, fixed risk score based on keyword matching, augmenting the model's probabilistic reasoning. |
| **LLM Agent Tools** | `populate_database` | A custom tool that serves as the **commit function**, validating the final LLM output, adding audit data, and triggering the A2A transfer. |
| **Sequential Agents** | Stage 1 ‚Üí Stage 2 Workflow | The entire process is a clear **pipeline** where the raw output of the initial analysis (Stage 1) is saved, retrieved, and then fed as the critical input to the formatting stage (Stage 2). |
| **Agent Powered by an LLM** | `client.models.generate_content` | The core intelligence driving the workflow, responsible for creative analysis in Stage 1 and enforcing structure in Stage 2. |

---

## üöÄ Getting Started: Setup and Installation

### 1. ‚öôÔ∏è Prerequisites

Before running the agent, ensure you have the following:

* **Python:** Version 3.9 or newer.
* **Gemini API Key:** Obtained from Google AI Studio.
* **Execution Environment:** A Jupyter-compatible environment (like **Kaggle Notebooks** or local VS Code) is highly recommended for managing secrets and displaying rich output.

### 2. üì¶ Installing Dependencies

Install all necessary libraries using `pip`. The dependencies are grouped by functionality:

```bash
# Core Gemini SDK and essential utilities
pip install google-genai requests

# Libraries required for the Kaggle/Jupyter environment and secret management
pip install kaggle-secrets ipython jupyter_server

# (Optional) If fully leveraging all Google ADK components (beyond this specific workflow)
# pip install google-adk

3. üîë Configuration and Authentication
A. Set the Gemini API Key
The agent is configured to securely retrieve your API key from the execution environment's secret manager:

Kaggle/Colab: Add your Gemini API Key to the Secrets utility under the exact name GOOGLE_API_KEY.

The initial code block handles setting this key as an environment variable.

B. External Service Configuration
The following constants define the target for the A2A transfer:

EXTERNAL_API_URL = "[https://api.external-service.com/process_contract](https://api.external-service.com/process_contract)" 
API_KEY = "YOUR_SECURE_API_KEY_12345" # Token used for A2A Bearer Authentication

üèóÔ∏è Detailed Workflow Breakdown
The agent executes a two-stage, controlled process:

Stage 1: Ingestion, Analysis, and Context Preservation
Authentication & Config: The process starts with secure key retrieval, client initialization, and setting up resilience (HTTP Retry Options).

File Ingestion: The client.files.upload() API uploads the contract image (contract01.png) and creates a permanent API reference.

Session Start: A unique SESSION_ID is created and initialized in the MemorySessionService.

LLM Call (Analysis): The first call to gemini-2.0-flash is made with the raw prompt and the file reference. The model is given the perform_risk_assessment tool.

Tool Execution: The LLM internally calls the risk assessment tool, feeding it relevant clauses, and incorporating the tool's deterministic JSON output (risk_score) into its narrative response.

State Save: The full narrative analysis text (response1.text) is saved to memory using MemorySessionService.save_data().

Stage 2: Structured Conversion and Data Integration
State Retrieval: The full narrative text is retrieved from memory.

LLM Call (Structuring): A second generate_content call is made. The prompt explicitly instructs the model to convert the retrieved narrative into strict JSON.

Structured Output Enforcement: The configuration uses response_schema=OUTPUT_SCHEMA and response_mime_type="application/json" to guarantee the output is a valid JSON object matching the required structure.

A2A Trigger: The resulting JSON is passed to populate_database (which simulates data insertion) and immediately initiates the send_data_to_external_system A2A call, confirming final data hand-off.

üíª Running the Agent Workflow (Step-by-Step)
Execution is divided into distinct phases:

1. ‚öôÔ∏è Initial Configuration and File Ingestion (Setup Phase)
Run the initial code cell that handles client creation and file upload.

Step,Action,Expected Output/Verification
Authentication,The script retrieves and sets the GOOGLE_API_KEY.,‚úÖ Gemini API key setup complete
File Upload,The script executes client.files.upload().,‚úÖ File successfully uploaded: files/...
Session Start,The unique SESSION_ID is created and stored in MemorySessionService.,‚úÖ Session created with ID: ...
Failure Check,"If ‚ùå Error: File not found... appears, STOP and correct the file path.",

2. üß† Workflow Execution (The Core Analysis)
A. Stage 1: Analysis & Risk Scoring
Action: Execute the code block containing the first client.models.generate_content call.

Process: The model analyzes the contract, internally calls the perform_risk_assessment tool.

B. Stage 2: Structuring & Finalization
Action: The subsequent code block is executed. It retrieves the raw text from memory and initiates the second generate_content call, enforcing the OUTPUT_SCHEMA structure.

Key Action: The validated JSON triggers the populate_database tool, which executes the simulated A2A transfer.

3. ‚úÖ Final Output and Cleanup
The script concludes by displaying the final result and ensuring resources are released.

Final Result Display: The code parses the final structured JSON and prints a color-coded summary, including the Overall Risk Score and Extracted Entities.

Cleanup (finally block): The program automatically calls MemorySessionService.delete_session and client.files.delete to manage resources and privacy.

Function Name,Role,Key Actions
MemorySessionService,State Manager,Saves and retrieves context (raw text) between sequential LLM calls.
perform_risk_assessment,Expert Tool,"Scans text for high-risk terms (e.g., ""NOTWITHSTANDING..."") and returns a deterministic risk rating."
populate_database,A2A Trigger Tool,"Validates the LLM's final JSON output, adds an audit timestamp, and initiates the external data transfer."
send_data_to_external_system,A2A Protocol,Formats data with Bearer authentication and calls the mock external endpoint.
